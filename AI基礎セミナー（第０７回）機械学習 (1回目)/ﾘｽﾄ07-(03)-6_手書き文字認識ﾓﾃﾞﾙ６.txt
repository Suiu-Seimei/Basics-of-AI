#********************************************************************/
# ﾘｽﾄ07-(03)-6_手書き文字認識ﾓﾃﾞﾙ６
#--------------------------------------------------------------------
# 「手書き文字認識ﾓﾃﾞﾙ６」
#  深層畳み込みﾆｭｰﾗﾙﾈｯﾄﾜｰｸ（DCNN）・・・７層、3×3の最大値ﾌﾟｰﾘﾝｸﾞ
#********************************************************************/
# 参照ﾗｲﾌﾞﾗﾘ
import numpy as np
np.random.seed(1)
from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from keras.optimizers import Adam
import time

#********************************************************************/
# reshape_for_model6                                                */
# ﾛｰﾄﾞした MNIST ﾃﾞｰﾀを「手書き文字認識ﾓﾃﾞﾙ６」                     */
# 用に変形したものを返す                                            */
#-------------------------------------------------------------------*/
# 引数：                                                            */
#   in_image ：入力画像：uint8（入力画像枚数,28,28)                 */
#   in_label ：入力画像が表す数値（0〜9）：uint8（入力画像枚数)     */
#-------------------------------------------------------------------*/
# 戻り値：                                                          */
#  (1) in_image を                                                  */
#    「３次元(入力画像枚数,28,28)、uint8(0〜255)」から              */
#    「４次元(入力画像枚数,28,28,1)、float32(0.0〜1.0)」            */
#     へ正規化したもの                                              */
#  (2) in_label を                                                  */
#    「１次元(入力画像枚数)、uint8(0〜8：入力画像が表す数値)）から  */
#    「1-of-k 符号化」で 10ｸﾗｽへ分類し「２次元(入力画像枚数,10)」   */
#     各ｸﾗｽへの所属確率を float32(0.0〜1.0)で表現したもの           */
#     へ変換したもの                                                */
#********************************************************************/
def reshape_for_model6(in_image, in_label):
    return  reshape_for_model2(in_image, in_label)


#********************************************************************/
# make_and_evaluate_model6                                          */
# 「手書き文字認識ﾓﾃﾞﾙ６」を作成してそれを評価する                  */
#   隠れ層の活性化関数は引数で指定可能                              */
#-------------------------------------------------------------------*/
# 「手書き文字認識ﾓﾃﾞﾙ６」                                          */
#  深層畳み込みﾆｭｰﾗﾙﾈｯﾄﾜｰｸ（DCNN）                                  */
#                                                                   */
# (1) 入力層から出力層に向けて一方通行で流れる(Sequential)。        */
# (2) 入力層の入力ﾃﾞｰﾀは、                                          */
# 　　(Y方向ｻｲｽﾞ, X方向ｻｲｽﾞ, 入力ﾁｬﾈﾙ数) = (28,28,1) とする。       */
# 　　「入力ﾁｬﾈﾙ数」はﾓﾉｸﾛ画像なので1(ｶﾗｰ画像なら3) 。              */
# 　　値は、0〜255 の 256 諧調のところを、                          */
# 　　255 で割って 0〜1 に正規化したものを用いる。                  */
#                                                                   */
# (3) 入力と出力の間に、中間層（隠れ層）を置く。                    */
# 　　中間層を以下の６段で構成する。                                */
#  (3.1) 中間層第１段は、畳み込み層で、                             */
# 　　　 ﾌｨﾙﾀ 3×3 を 16枚で、Padding無しで、畳み込む。             */
#  (3.2) 中間層第２段は、畳み込み層で、                             */
# 　　　 ﾌｨﾙﾀ 3×3 を 32枚で、Padding無しで、畳み込む。             */
#  (3.3) 中間層第３段は、3×3の最大値ﾌﾟｰﾘﾝｸﾞ層。                    */
#  (3.4) 中間層第４段は、畳み込み層で、                             */
# 　　　 ﾌｨﾙﾀ 3×3 を 64枚で、Padding無しで、畳み込む。             */
#  (3.5) 中間層第５段は、3×3の最大値ﾌﾟｰﾘﾝｸﾞ層で、                  */
# 　　　 ﾄﾞﾛｯﾌﾟｱｳﾄ率を 0.25 とする。                                */
# 　　　 この出力を、Flatten層を通して一次元化する。                */
# 　　　 一次元化したﾉｰﾄﾞを、中間層第６段の各ﾉｰﾄﾞとの間で全結合する。*/
#  (3.6) 中間層第６段は、全結合層で、ﾄﾞﾛｯﾌﾟｱｳﾄ率を 0.25 とする。    */
# 　　　 各ﾉｰﾄﾞを、出力層の各ﾉｰﾄﾞとの間で全結合させる。             */
#                                                                   */
# (4) 出力層のﾉｰﾄﾞ数は、10 (入力画像の文字の種類(0〜9)の数)である。 */
# 　　ﾃﾞｰﾀ型は「float32 (入力画像枚数,10)」で、                     */
# 　　入力画像の各ｸﾗｽへの所属確率[0〜1]を表す。                     */
# 　　中間層の出力を「Flatten」層を通すことで、                     */
# 　　「28×28×8枚×入力ﾁｬﾈﾙ数」という                             */
# 　　４次元のﾃﾞｰﾀを一次元化して、出力層との間で全結合させる。      */
#                                                                   */
# (5) 中間層の活性化関数は「relu」                                  */
# (6) 出力層の活性化関数は「softmax」                               */
# (7) 損失関数(誤差を計算する関数)は「categorical_crossentropy」    */
# (8) 学習方法(モデルの最適化方法)は「Adam」                        */
# (9) 学習時には「ｴﾎﾟｯｸ数」として10、                               */
# 　　「ﾊﾞｯﾁｻｲｽﾞ」として「1000」で学習を行う。                      */
#-------------------------------------------------------------------*/
# 引数：                                                            */
#   title    : 表示用ﾀｲﾄﾙ                                           */
#   actvFunc : 隠れ層の活性化関数                                   */
#-------------------------------------------------------------------*/
# 戻り値：                                                          */
#   (1) 作成したﾓﾃﾞﾙ                                                */
#********************************************************************/
def make_and_evaluate_model6(title, actvFunc):

    print("*********************************************************")
    print(title)
    print("*********************************************************")

    #=================================================================
    # ﾛｰﾄﾞしたMNIST ﾃﾞｰﾀを「手書き文字認識ﾓﾃﾞﾙ６」用に変形する。
    #=================================================================
    inTrain, outTrain = reshape_for_model6(x_train, y_train)
    inTest, outTest = reshape_for_model6(x_test, y_test)

    titlestr = ["modified ...", "inTrain", "outTrain", "inTest", "outTest"]
    print_MNIST_attr(titlestr, inTrain, outTrain, inTest, outTest)

    #=================================================================
    # 「手書き文字認識ﾓﾃﾞﾙ６」を作成
    #=================================================================
    np.random.seed(1)

    predModel = Sequential()
    predModel.add(Conv2D(16, (3, 3),
        input_shape=(IMG_SIZE_Y, IMG_SIZE_X, 1), activation=actvFunc))
    predModel.add(Conv2D(32, (3, 3), activation=actvFunc))
    predModel.add(MaxPooling2D(pool_size=(3, 3)))
    predModel.add(Conv2D(64, (3, 3), activation=actvFunc))
    predModel.add(MaxPooling2D(pool_size=(3, 3)))
    predModel.add(Dropout(0.25))
    predModel.add(Flatten())
    predModel.add(Dense(128, activation=actvFunc))
    predModel.add(Dropout(0.25))
    predModel.add(Dense(IMG_CLASS_NO, activation='softmax'))
    predModel.compile(loss='categorical_crossentropy',
        optimizer=Adam(), metrics=['accuracy'])

    predModel.summary()

    #=================================================================
    # 「手書き文字認識ﾓﾃﾞﾙ６」を学習し、
    # 学習状況を、ｴﾎﾟｯｸ回数の時系列でｸﾞﾗﾌ表示する
    #=================================================================
    epochNo = 10
    batchSize = 1000

    startTime = time.time()
    history = predModel.fit(inTrain, outTrain, 
        epochs=epochNo, batch_size=batchSize,
        verbose=0, validation_data=(inTest, outTest))
    score = predModel.evaluate(inTest, outTest, verbose=0)
    endTime = time.time()

    print('Test loss:', score[0])
    print('Test accuracy:', score[1])
    print("Computation time:{0:.3f} sec".format(time.time() - startTime))

    plot_learning_curve( history, epochNo )

    #=================================================================
    # 「手書き文字認識ﾓﾃﾞﾙ６」で、
    # MINTSTの検証用ﾃﾞｰﾀの最初の50枚で分類結果を表示する。
    #=================================================================
    pred_test_and_show_result(predModel, inTest, y_test, IMG_SIZE_X, IMG_SIZE_Y, 50)

    return predModel


#********************************************************************/
# 「手書き文字認識ﾓﾃﾞﾙ６」で 
#  活性化関数を「relu」でﾓﾃﾞﾙを作成して評価する。
#********************************************************************/
predModel = make_and_evaluate_model6(
    "「深層畳み込みﾆｭｰﾗﾙﾈｯﾄﾜｰｸ（DCNN）」で活性化関数は「relu」",'relu')


#********************************************************************/
# 「手書き文字認識ﾓﾃﾞﾙ６」で、
# 自作の画像の分類結果を表示する。
#********************************************************************/
pred_myData_and_show_result("手書き文字認識ﾓﾃﾞﾙ６（DCNN,relu）", 
    predModel, reshape_for_model6)

