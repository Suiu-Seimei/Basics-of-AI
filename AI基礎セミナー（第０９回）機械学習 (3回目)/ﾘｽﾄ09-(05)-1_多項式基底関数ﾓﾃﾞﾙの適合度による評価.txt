#************************************************************************
# ﾘｽﾄ09-(05)-1_多項式基底関数ﾓﾃﾞﾙの適合度による評価
#------------------------------------------------------------------------
#「秋田」の2月の平均気温の年系列のデータについて、
# 先頭の9割のデータからＭ次の多項式基底関数ﾓﾃﾞﾙを
# 「ムーア・ペンローズの擬似逆行列」を用いた解析解を導出して作成します。
#
# 作成したﾓﾃﾞﾙを用いて、全期間の計算値を求めて実測値と比較することにより、
# ﾓﾃﾞﾙを作成した期間と、それ以外の期間について、
# その二乗平均平方根誤差(RMSE)と決定係数(R2)を算出して評価します。
#************************************************************************
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

#************************************************************************/
# データ (「秋田」における2月の平均気温の年系列)
#************************************************************************/
# データ (年)
yyyy= [1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,
       1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,
       1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,
       1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,
       1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,
       1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,
       2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020]

# データ (2月の平均気温)
tFeb = [-2.6,-0.9,-1.9,-2.1,-0.4,-3.7,-1.5,0.6,-1.7,-1.3,-3.6,-0.9,-1.5,-0.9,-1.3,0.3,-0.9,-2.1,
        -0.9,-1.6,0.5,-0.8,-2.4,-2.2,-2.2,-2.0,-2.0,-2.2,-0.5,1.0,-1.7,-0.6,-1.0,-0.5,-1.2,-1.9,-1.3,-1.9,
        -0.9,0.9,-1.9,-1.7,-2.4,-0.9,-2.9,-1.5,-2.3,0.7,-3.0,-0.5,-2.8,-1.1,0.2,-1.5,0.2,-1.2,-1.8,-1.5,
        -0.7,-2.6,-0.8,-1.9,-3.5,-0.5,-2.0,-0.9,2.3,0.0,-0.2,-2.8,-1.5,0.7,0.2,-1.2,-1.1,1.2,2.1,1.1,
        -0.7,-0.1,0.0,-1.0,-1.0,0.1,-0.3,-1.2,-0.8,-0.1,-0.1,0.3,1.6,-0.5,-0.5,0.2,-0.9,-2.5,2.0,-1.4,
         0.4,-1.0,-0.5,-2.3,0.5,-1.6,0.2,-2.0,1.9,3.0,0.5,0.5,2.1,1.3,1.1,0.3,1.3,1.3,0.5,0.2,
        -0.8,1.9,0.7,2.0,-0.5,0.9,2.7,0.0,1.4,0.4,1.1,-1.0,-0.5,-0.1,2.3,0.9,1.3,-0.9,1.5,2.5 ]

#********************************************************************/
# f_RMSE                                                            */
# 計算値と実測値の二乗平均平方根誤差（RMSE)を算出する。             */
#-------------------------------------------------------------------*/
# 引数：                                                            */
#   t   : 実測値（教師ﾃﾞｰﾀ）                                        */
#   y   : 予測値                                                    */
#-------------------------------------------------------------------*/
# 戻り値：二乗平均平方根誤差（RMSE)                                 */
#********************************************************************/
def  f_RMSE(t, y):
    if (len(t) <= 0):
        return 0.0

    err2Sum = 0.0
    for n in range(0, len(t)):
        err2Sum = err2Sum + (t[n] - y[n])**2
    return np.sqrt(err2Sum / len(t))
    
#********************************************************************/
# f_R2                                                              */
# 計算値と実測値の決定係数(Ｒ2)を算出する。                         */
#-------------------------------------------------------------------*/
# 引数：                                                            */
#   t   : 実測値（教師ﾃﾞｰﾀ）                                        */
#   y   : 予測値                                                    */
#-------------------------------------------------------------------*/
# 戻り値：決定係数(Ｒ2)                                             */
#********************************************************************/
def  f_R2(t, y):
    if (len(t) <= 0):
        return 0.0

    tmean = np.mean(t)
    ess = 0.0
    tss = 0.0
    for n in range(0, len(t)):
        ess = ess + (y[n] - tmean)**2
        tss = tss + (t[n] - tmean)**2
    return ess / tss
 
#********************************************************************/
# f_PseudoInvMatrix                                                 */
# Ｍ次の多項式基底関数ﾓﾃﾞﾙの回帰曲線を、                            */
# ムーア・ペンローズの擬似逆行列を解くことにより、算出する。        */
#-------------------------------------------------------------------*/
# 引数：                                                            */
#   x ：説明変数のリスト（ﾃﾞｰﾀの組分）                              */
#   t ：目的変数のリスト（ﾃﾞｰﾀの組分）                              */
#   orderM：多項式基底関数ﾓﾃﾞﾙの多項式の最大次数                    */  
#-------------------------------------------------------------------*/
# 戻り値：                                                          */
#   wList ：作成したＭ次の多項式基底関数ﾓﾃﾞﾙの偏回帰係数（Ｍ+1個分）*/
#********************************************************************/
def f_PseudoInvMatrix( x, t, orderM ):
    # 基底関数の行列Φ(mtrxF)
    dataN = len(t)
    mtrxF = np.zeros([dataN, orderM+1])
    for n in range(0, dataN):
        mtrxF[n,0] = 1
        for m in range(1, orderM+1):
            mtrxF[n,m] = x[n]**m

    # 偏回帰係数を算出して、回帰ﾓﾃﾞﾙを作成
    inv_FtF = np.linalg.inv(np.dot(mtrxF.T, mtrxF))
    mtrxM = np.dot(inv_FtF, mtrxF.T) # ムーア・ペンローズの擬似逆行列
    wList = np.dot(mtrxM, t)    # Ｍ次元線形回帰ﾓﾃﾞﾙの解析解

    print("(wList)=({0})".format(wList))
    return wList

#********************************************************************/
# f_Standardize                                                     */
# 指定したデータを標準化し、その結果と平均・標準偏差を返す。        */
#-------------------------------------------------------------------*/
# 引数：                                                            */
#   d ：対象のデータリスト（ﾃﾞｰﾀの組分）                            */
#-------------------------------------------------------------------*/
# 戻り値：                                                          */
# (第１返値) z    ：指定したデータの標準化結果                      */
# (第２返値) dAve ：指定したデータの平均                            */
# (第３返値) dStd ：指定したデータの・標準偏差                      */
#********************************************************************/
def f_Standardize( d ):
    dAve = np.average(d)
    dStd = np.std(d)

    if dStd == 0.0 :
        return d, dAve, dStd
    else:
        z = np.zeros([len(d)])
        for n in range(0, len(d)):
            z[n] = (d[n] - dAve)/ dStd
        return z, dAve, dStd

#********************************************************************/
# f_PredAndPlot                                                     */
# 先頭の9割のデータからＭ次の多項式基底関数ﾓﾃﾞﾙを作成し、           */
# モデルの計算値と、実測値を比較することにより、                    */
# その精度指標とグラフを表示する。                                  */
#-------------------------------------------------------------------*/
# 引数：                                                            */
#   xList ：観測値のうち説明変数のリスト（ﾃﾞｰﾀの組分）              */
#   tList ：観測値のうち目的変数のリスト（ﾃﾞｰﾀの組分）              */
#   orderM：多項式基底関数ﾓﾃﾞﾙの多項式の最大次数                    */  
#-------------------------------------------------------------------*/
# 戻り値：                                                          */
# (第1返値) 学習ﾃﾞｰﾀ（先頭の9割のﾃﾞｰﾀ）の最後の説明変数の配列添え字 */
# (第2返値) 学習ﾃﾞｰﾀ（先頭の9割のﾃﾞｰﾀ）の二乗平均平方根誤差（RMSE)  */
# (第3返値) 学習ﾃﾞｰﾀ（先頭の9割のﾃﾞｰﾀ）決定係数(Ｒ2)の平方根（相関係数）*/
# (第4返値) 評価ﾃﾞｰﾀ（最後の1割のﾃﾞｰﾀ）二乗平均平方根誤差（RMSE)    */
# (第5返値) 評価ﾃﾞｰﾀ（最後の1割のﾃﾞｰﾀ）決定係数(Ｒ2)の平方根（相関係数）*/
#********************************************************************/
def f_PredAndPlot( x, t, orderM ):
    print("//=======================================================")
    print("// 多項式基底関数ﾓﾃﾞﾙの次数 M={0}".format(orderM))
    print("//=======================================================")

    # データ数
    dataN = len(t)
    
    # 説明変数について、計算の収束と桁あふれ防止用にﾃﾞｰﾀの標準化を施す
    xList, xAve, xStd = f_Standardize( x )

    # 目的変数について、計算の収束と桁あふれ防止用にﾃﾞｰﾀの標準化を施す
    tList, tAve, tStd = f_Standardize( t )

    # 先頭の９割のデータから偏回帰係数を算出して、回帰ﾓﾃﾞﾙを作成
    dataNc = int(np.trunc(dataN * 0.9))
    wList = f_PseudoInvMatrix( xList[:dataNc], tList[:dataNc], orderM )

    # 作成した回帰ﾓﾃﾞﾙで、座標を計算
    y = np.zeros(dataN)
    for n in range(0, dataN):
        xmList = np.zeros([orderM+1])
        for m in range(0, orderM+1):
            xmList[m] = xList[n]**m
        y[n] = (np.dot(wList, xmList) * tStd) + tAve

    # RMSE、R2を計算（ﾓﾃﾞﾙ作成用の学習ﾃﾞｰﾀ（先頭の9割のデータ））
    o_TrainRmse = f_RMSE(t[:dataNc], y[:dataNc])
    o_TrainR2 = f_R2(t[:dataNc], y[:dataNc])
    o_TrainR = np.sqrt(o_TrainR2)
    print("Train: RMSE={0}, R={1}".format(o_TrainRmse, o_TrainR))

    # RMSE、R2を計算（評価用のﾃﾞｰﾀ（最後の1割のデータ））
    o_TestRmse = f_RMSE(t[dataNc:], y[dataNc:])
    o_TestR2 = f_R2(t[dataNc:], y[dataNc:])
    o_TestR = np.sqrt(o_TestR2)
    print("Test : RMSE={0}, R={1}".format(o_TestRmse, o_TestR))

    # グラフ表示範囲
    diagList = np.linspace(int(np.min(t)-1),int(np.max(t)+1), 100)
    plt.figure(figsize=(15, 3))

    # 時系列
    plt.subplot(1, 2, 1)
    plt.title("Time series of February Temp(C) at Akita")
    plt.plot(x[:dataNc], t[:dataNc], marker='o', linestyle='None', 
             markeredgecolor='black', color='cornflowerblue') # 学習ﾃﾞｰﾀ
    plt.plot(x[dataNc:], t[dataNc:], marker='x', linestyle='None', 
             markeredgecolor='black', color='blue') # 試験ﾃﾞｰﾀ
    plt.plot(x[:dataNc], y[:dataNc], color='red', linewidth=3, linestyle='-', ) # 学習ﾃﾞｰﾀ
    plt.plot(x[dataNc:], y[dataNc:], color='red', linewidth=3, linestyle=':', ) # 試験ﾃﾞｰﾀ
    plt.xlim(np.min(x)-1, np.max(x)+1)
    plt.ylim(np.min(t)-1, np.max(t)+1)
    plt.xlabel("Year")
    plt.ylabel("Temp.(C)")
    plt.grid(True)

    # 観測値と予測値の相関分布
    plt.subplot(1, 2, 2)
    plt.title("Scatter plot of February Temp(C) at Akita")
    plt.plot(t[:dataNc], y[:dataNc], marker='o', linestyle='None', 
             markeredgecolor='black', color='cornflowerblue') # 学習ﾃﾞｰﾀ
    plt.plot(t[dataNc:], y[dataNc:], marker='x', linestyle='None', 
             markeredgecolor='black', color='blue') # 試験ﾃﾞｰﾀ
    plt.plot(diagList, diagList, color='green', linewidth=3, linestyle='--', )
    plt.xlim(np.min(t)-1, np.max(t)+1)
    plt.ylim(np.min(t)-1, np.max(t)+1)
    plt.xlabel("Temp.(C) Observed")
    plt.ylabel("Temp.(C) Predicted")
    plt.grid(True)

    plt.show()

    return  dataNc-1, o_TrainRmse, o_TrainR, o_TestRmse, o_TestR

#************************************************************************/
# メイン処理                                                            */
#************************************************************************/
maxM = 10  # 多項式基底関数ﾓﾃﾞﾙの最大次数
mList = np.zeros(maxM)
trainLastI = 0
trainRmse = np.zeros(maxM)
trainR = np.zeros(maxM)
testRmse = np.zeros(maxM)
testR = np.zeros(maxM)

for m in range(0, maxM):
    mList[m] = m+1
    trainLastI, trainRmse[m], trainR[m],testRmse[m], testR[m] = f_PredAndPlot( yyyy, tFeb, m+1 )
    
# 多項式基底関数ﾓﾃﾞﾙの次数毎の適合度の変化
plt.figure(figsize=(15, 3))

plt.subplot(1, 2, 1)
plt.title("RMSE of train({0}-{1}), test({2}-{3})".format(
    yyyy[0], yyyy[trainLastI], yyyy[trainLastI+1], yyyy[len(yyyy)-1]))
plt.plot(mList, trainRmse, color='blue', linewidth=3, linestyle='-', label='$RMSE (train)$')
plt.plot(mList, testRmse, color='blue', linewidth=3, linestyle=':', label='$RMSE (test)$')
plt.xlim(1, maxM)
plt.ylim(0, 3)
plt.xlabel("order M")
plt.ylabel("RMSE")
plt.grid(True)

plt.subplot(1, 2, 2)
plt.title("R of train({0}-{1}), test({2}-{3})".format(
    yyyy[0], yyyy[trainLastI], yyyy[trainLastI+1], yyyy[len(yyyy)-1]))
plt.plot(mList, trainR, color='red', linewidth=3, linestyle='-', label='$R (train)$')
plt.plot(mList, testR, color='red', linewidth=3, linestyle=':', label='$R (test)$')
plt.xlim(1, maxM)
plt.ylim(0, 3)
plt.xlabel("order M")
plt.ylabel("R")
plt.grid(True)
plt.show()
